# ğŸš¨ RealShield

<div align="center">

![Version](https://img.shields.io/badge/version-1.0.0-blue.svg)
![Python](https://img.shields.io/badge/python-3.9+-green.svg)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-3.4+-orange.svg)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-3.5+-yellow.svg)
![Cassandra](https://img.shields.io/badge/Cassandra-4.1+-red.svg)
![Docker](https://img.shields.io/badge/Docker-24.0+-blue.svg)

**Un systÃ¨me complet de dÃ©tection de fraude en temps rÃ©el simulant la surveillance de transactions bancaires avec moteur de rÃ¨gles mÃ©tier**

[Architecture](#-architecture) â€¢ [FonctionnalitÃ©s](#-fonctionnalitÃ©s) â€¢ [DÃ©marrage Rapide](#-dÃ©marrage-rapide) â€¢ [DÃ©monstration](#-dÃ©monstration) â€¢ [Stack Technique](#-stack-technique)

</div>

## ğŸ“– AperÃ§u

Ce projet implÃ©mente un **systÃ¨me de dÃ©tection de fraude en temps rÃ©el de qualitÃ© production** qui simule la surveillance de transactions bancaires. Il traite les donnÃ©es de transaction en flux, applique des rÃ¨gles mÃ©tier sophistiquÃ©es pour la dÃ©tection de fraude et fournit une visualisation en temps rÃ©el via un tableau de bord interactif.

### ğŸ¯ CapacitÃ©s Principales

- **Ingestion de donnÃ©es en temps rÃ©el** avec Apache Kafka
- **Moteur de rÃ¨gles mÃ©tier** pour la dÃ©tection de fraude
- **Traitement de flux** avec Apache Spark Streaming
- **Stockage scalable** avec Cassandra
- **Tableau de bord moderne** avec React/TypeScript
- **Containerisation complÃ¨te** avec Docker

---

## ğŸ—ï¸ Architecture

### Vue d'Ensemble du SystÃ¨me

```mermaid
graph TB
    A[ğŸ“Š GÃ©nÃ©rateur de DonnÃ©es] -->|Kafka| B[âš¡ Cluster Kafka]
    B -->|Stream| C[ğŸ” Spark Streaming]
    C -->|Moteur de RÃ¨gles| D[ğŸ›¡ï¸ DÃ©tection de Fraude]
    C -->|Enrichissement| E[ğŸ‘¤ Profils Utilisateurs]
    D -->|Stockage| F[ğŸ’¾ Cassandra]
    E -->|Stockage| F
    F -->|API| G[ğŸŒ FastAPI]
    G -->|Tableau de bord| H[ğŸ“ˆ Dashboard React]
    
    style A fill:#e1f5fe
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#ffebee
    style E fill:#e8f5e8
    style F fill:#fff8e1
    style G fill:#e0f2f1
    style H fill:#fce4ec
```

### ğŸ”„ Flux de DonnÃ©es

1. **GÃ©nÃ©ration de donnÃ©es** â†’ Transactions synthÃ©tiques avec motifs de fraude rÃ©alistes
2. **Ingestion de flux** â†’ Topics Kafka pour traitement en temps rÃ©el
3. **Traitement** â†’ Spark Streaming avec enrichissement et dÃ©tection
4. **Stockage** â†’ Cassandra pour persistance scalable
5. **Visualisation** â†’ Tableau de bord React avec mises Ã  jour en temps rÃ©el

---

## ğŸš€ FonctionnalitÃ©s

### ğŸ” Moteur de DÃ©tection de Fraude

| FonctionnalitÃ© | Description | ImplÃ©mentation |
|---------------|-------------|----------------|
| **Voyage Impossible** | DÃ©tecte les transactions depuis des locations gÃ©ographiquement impossibles | RÃ¨gles MÃ©tier |
| **Alerte Montant Ã‰levÃ©** | Signale les transactions > 3x la moyenne utilisateur | RÃ¨gles MÃ©tier |
| **Score de Risque** | Ã‰valuation du risque au niveau utilisateur | Calcul Temps RÃ©el |
| **Pays Ã‰tranger** | DÃ©tecte les transactions hors du pays de rÃ©sidence | RÃ¨gles MÃ©tier |

### ğŸ“Š Tableau de Bord Temps RÃ©el

![Vue d'ensemble du Dashboard](docs/images/dashboard-overview.png)

#### Composants du Dashboard :
- **ğŸŒ Carte des Transactions Live** - Visualisation gÃ©ographique en temps rÃ©el
- **ğŸ“ˆ MÃ©triques KPI** - Transactions/min, alertes actives, taux suspect
- **ğŸš¨ Ticker d'Alertes Live** - Notifications de fraude en temps rÃ©el
- **ğŸ“Š Analytics** - Tendances, patterns et insights
- **ğŸ‘¤ Profils Utilisateurs** - Historique des transactions et scores de risque

---

## ğŸ› ï¸ Stack Technique

### Backend & Data Engineering
- **Apache Kafka 3.4** - Streaming de donnÃ©es en temps rÃ©el
- **Apache Spark 3.5** - Traitement de flux
- **Cassandra 4.1** - Stockage NoSQL scalable
- **FastAPI** - API REST avec documentation automatique
- **Python 3.9+** - Traitement de donnÃ©es

### Frontend & Visualisation
- **React 18** - Framework UI moderne
- **TypeScript** - DÃ©veloppement type-safe
- **Tailwind CSS** - Styling utility-first
- **Recharts** - Visualisation de donnÃ©es
- **Next.js** - Framework React

### Infrastructure
- **Docker & Docker Compose** - Containerisation
- **Bitnami Spark** - Images Spark prÃªtes pour la production
- **Confluent Kafka** - Distribution Kafka entreprise

---

## âš¡ DÃ©marrage Rapide

### PrÃ©requis

- Docker & Docker Compose
- Python 3.9+

### ğŸ³ DÃ©ploiement Docker (RecommandÃ©)

```bash
# Cloner le repository
git clone https://github.com/sanogomamadou/project-fraud-real-time-detection.git
cd project-fraud-real-time-detection

# DÃ©marrer tous les services
docker-compose up -d

# Attendre l'initialisation des services (2-3 minutes)
docker-compose logs -f

# AccÃ©der aux applications :
# Dashboard: http://localhost:3000
# Documentation API: http://localhost:8000/docs
# Spark UI: http://localhost:8080
```

### ğŸ”§ Setup Manuel (DÃ©veloppement)

```bash
# 1. DÃ©marrer l'infrastructure
docker-compose up -d

# 2. GÃ©nÃ©rer les profils utilisateurs
python src/generate_user_profiles.py

# 3. DÃ©marrer le gÃ©nÃ©rateur de donnÃ©es
python generator/generator.py --bootstrap-server localhost:29092 --topic transactions --rate 2 --num-users 100

# 4. DÃ©marrer Spark streaming (nouveau terminal)
pip install pyyaml pathlib
docker-compose exec spark-master bash  
spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.0,com.datastax.spark:spark-cassandra-connector_2.12:3.4.0 /opt/workspace/spark-streaming/fraud_detection.py


# 5. DÃ©marrer l'API (nouveau terminal)
cd api && uvicorn main:app --reload

# 6. DÃ©marrer le dashboard (nouveau terminal)
cd dashboard && npm run dev
```

---

## ğŸ“ Structure du Projet

```
fraud-real-time-project/
â”œâ”€â”€ ğŸ³ docker-compose.yml          # Orchestration multi-services
â”œâ”€â”€ ğŸ“Š dashboard/                  # Frontend React TypeScript
â”œâ”€â”€ ğŸ”Œ api/                        # Backend FastAPI
â”œâ”€â”€ âš¡ spark-streaming/            # Jobs de traitement Spark
â”œâ”€â”€ ğŸ² generator/                  # Simulation de donnÃ©es
â”œâ”€â”€ ğŸ“¥ consumers/                  # Consumers Kafka
â”œâ”€â”€ ğŸ’¾ data/                       # Fichiers de donnÃ©es statiques
â””â”€â”€ ğŸ“š docs/                       # Documentation & captures d'Ã©cran
```

### PlongÃ©e dans les Composants ClÃ©s

#### 1. ğŸ² GÃ©nÃ©rateur de DonnÃ©es (`generator/generator.py`)
```python
# GÃ©nÃ¨re des motifs de transaction rÃ©alistes
- Transactions normales : 95% du trafic
- Motifs de fraude : 5% avec signatures spÃ©cifiques
- ModÃ©lisation du comportement utilisateur avec patterns gÃ©ographiques
- Streaming temps rÃ©el vers les topics Kafka
```

#### 2. âš¡ Spark Streaming (`spark-streaming/`)
```python
# Pipeline de traitement temps rÃ©el
1. Consumer Kafka â†’ Lit les flux de transactions
2. Enrichissement des donnÃ©es â†’ Jointure avec profils utilisateurs
3. Moteur de rÃ¨gles â†’ Applique les rÃ¨gles de dÃ©tection de fraude
4. Writer Cassandra â†’ Persiste les rÃ©sultats
```

#### 3. ğŸŒ Couche API (`api/`)
```python
# Endpoints FastAPI
@app.get("/transactions/feed")     # Flux de transactions temps rÃ©el
@app.get("/fraud/alerts")          # Alertes de fraude actives
@app.get("/health")                # Statut de santÃ© du systÃ¨me
```

#### 4. ğŸ“Š Tableau de Bord (`dashboard/`)
```typescript
// Composants React temps rÃ©el
<TransactionMap />     // Visualisation gÃ©ographique live
<LiveTicker />         // Flux d'alertes temps rÃ©el
<KpiCards />           // Tableau de bord des mÃ©triques clÃ©s
<AnalyticsContent />   // Analytics avancÃ©s
```

---

## ğŸ¯ RÃ¨gles de DÃ©tection de Fraude

### ImplÃ©mentation des RÃ¨gles MÃ©tier

```python
# DÃ©tection Montant Ã‰levÃ©
montant > moyenne_utilisateur * 3

# Anomalies GÃ©ographiques  
pays_actuel != pays_rÃ©sidence_utilisateur

# ContrÃ´le de VÃ©locitÃ©
nombre_transactions > 5 par fenÃªtre de 10 minutes

# Seuil de Risque
score_risque_utilisateur > 0.7


```

### Types de Fraude SimulÃ©s

- **ğŸ›« Voyage Impossible** : Transactions depuis des pays Ã©loignÃ©s en peu de temps
- **ğŸ’¸ Montant Anormal** : DÃ©penses significativement supÃ©rieures aux habitudes
- **ğŸŒ Pays Ã  Risque** : Transactions depuis des zones gÃ©ographiques inhabituelles

---

## ğŸ“Š DÃ©monstration & Captures d'Ã©cran

### Tableau de Bord Temps RÃ©el
![Dashboard Principal](docs/images/dashboard-overview.png)
*Surveillance en direct avec cartes KPI et carte des transactions*

### Inspection USER
![Vue USER](docs/images/user-ins.png)
*Visualisation du profil d'un utilisateur et de ses activitÃ©s*


---

## ğŸ”§ Documentation API

### AperÃ§u des Endpoints

| MÃ©thode | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/transactions/feed` | Flux de transactions temps rÃ©el |
| `GET` | `/fraud/alerts` | Alertes de fraude actives |
| `GET` | `/health` | Statut de santÃ© du systÃ¨me |
| `GET` | `/transactions/user/{user_id}` | Transactions spÃ©cifiques utilisateur |

### Exemple d'Utilisation

```bash
# Obtenir les transactions rÃ©centes
curl "http://localhost:8000/transactions/feed?limit=10"

# VÃ©rifier la santÃ© du systÃ¨me
curl "http://localhost:8000/health"

# AccÃ©der Ã  la documentation API
# http://localhost:8000/docs
```

---

## ğŸ“ Acquis d'Apprentissage

Ce projet dÃ©montre des **compÃ©tences avancÃ©es en Data Engineering** :

### ğŸ—ï¸ Architecture & Design
- Architecture microservices avec design event-driven
- Patterns de traitement de flux temps rÃ©el
- StratÃ©gies de stockage de donnÃ©es scalable
- DÃ©ploiement containerisÃ©

### ğŸ”§ ImplÃ©mentation Technique
- **Apache Kafka** : Streaming d'Ã©vÃ©nements et messagerie
- **Spark Structured Streaming** : Traitement de donnÃ©es temps rÃ©el
- **Cassandra** : Design de base de donnÃ©es haute performance en Ã©criture
- **FastAPI** : DÃ©veloppement d'API web Python moderne
- **React/TypeScript** : DÃ©veloppement frontend de qualitÃ© entreprise

### ğŸ“ˆ Concepts de Data Engineering
- Pipelines ETL temps rÃ©el
- Enrichissement de donnÃ©es et feature engineering
- Monitoring et observabilitÃ©
- QualitÃ© des donnÃ©es et validation

---

## ğŸš€ ConsidÃ©rations Production

### StratÃ©gies de Scaling
- **Kafka** : Partitionnement et groupes de consumers
- **Spark** : Mode cluster avec multiples workers
- **Cassandra** : ModÃ©lisation des donnÃ©es pour les patterns de requÃªte
- **API** : Load balancing et caching

---

## ğŸ¤ Contribution

Ce projet, bien que principalement une dÃ©monstration de capacitÃ©s en Data Engineering, les contributions et suggestions sont les bienvenues !


---

## ğŸ“„ Licence

Ce projet est dÃ©veloppÃ© Ã  des fins Ã©ducatives. Tout le code est disponible pour l'apprentissage et la dÃ©monstration.

---

## ğŸ‘¨â€ğŸ’» Auteur

**Mamadou SANOGO**  
*Ã‰tudiant en BIG DATA & IA*  
- ğŸ“§ Email : mamadou.sanogo@uir.ac.ma 
- ğŸ’¼ LinkedIn : [MAMADOU SANOGO](www.linkedin.com/in/mamadou-sanogo-3b22a9263)  

---


<div align="center">

### â­ Si ce projet vous a aidÃ© dans votre parcours d'apprentissage, n'hÃ©sitez pas Ã  lui donner une Ã©toile !


</div>
```
